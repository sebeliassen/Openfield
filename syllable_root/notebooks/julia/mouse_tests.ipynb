{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Statistic: 6.27970389176415\n",
      "P-value: 0.9999878331262626\n",
      "Degrees of Freedom: 27\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_df(df, column):\n",
    "    # Normalize the counts in each DataFrame by its total length (number of rows)\n",
    "    syllable_counts = df[column].value_counts()\n",
    "    normalized_counts = syllable_counts / len(df)\n",
    "    return normalized_counts\n",
    "\n",
    "def chi_square_test_syllables_normalized_per_df(pre_dfs, post_dfs, column='syllable_name'):\n",
    "    # Step 1: Normalize counts for each pre-amphetamine DataFrame\n",
    "    pre_normalized = [normalize_df(df, column) for df in pre_dfs]\n",
    "    \n",
    "    # Step 2: Normalize counts for each post-amphetamine DataFrame\n",
    "    post_normalized = [normalize_df(df, column) for df in post_dfs]\n",
    "    \n",
    "    # Step 3: Sum up the normalized counts across all DataFrames in each group\n",
    "    pre_counts = pd.concat(pre_normalized, axis=1).sum(axis=1)\n",
    "    post_counts = pd.concat(post_normalized, axis=1).sum(axis=1)\n",
    "    \n",
    "    # Step 4: Combine the normalized counts into a single DataFrame\n",
    "    combined_counts = pd.DataFrame({\n",
    "        'pre': pre_counts,\n",
    "        'post': post_counts\n",
    "    }).fillna(0)  # Fill NaN values with 0 for missing syllables\n",
    "    \n",
    "    # Step 5: Perform Chi-Square test on the normalized counts\n",
    "    chi2, p, dof, expected = chi2_contingency(combined_counts.T)\n",
    "\n",
    "    # Return Chi-Square statistic, p-value, degrees of freedom, expected frequencies, and combined counts\n",
    "    return chi2, p, dof, expected, combined_counts\n",
    "\n",
    "# Example usage:\n",
    "chi2, p, dof, expected, combined_counts = chi_square_test_syllables_normalized_per_df(pre_dfs, post_dfs)\n",
    "\n",
    "print(f\"Chi-Square Statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "\n",
    "# Create the DataFrame for expected frequencies\n",
    "#expected_df = pd.DataFrame(expected, index=['pre', 'post'], columns=combined_counts.columns)\n",
    "\n",
    "# Display the expected frequencies\n",
    "#print(f\"Expected Frequencies:\\n{expected_df}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = [normalize_df(df, 'syllable_name') for df in pre_dfs]\n",
    "lst2 = [normalize_df(df, 'syllable_name') for df in post_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lst1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n",
      "\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mlst1\u001b[49m[i])\n",
      "\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m35\u001b[39m)\n",
      "\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(lst2[i])\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lst1' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(lst1[i])\n",
    "    print('#'*35)\n",
    "    print(lst2[i])\n",
    "    print('#'*35)\n",
    "    print('#'*35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Difference: 20486.399999999998\n",
      "P-value: 0.545\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def permutation_test_syllables(pre_counts, post_counts, n_permutations=1000):\n",
    "    # Calculate the actual difference in means\n",
    "    actual_diff = post_counts.mean() - pre_counts.mean()\n",
    "\n",
    "    # Combine the counts and perform permutations\n",
    "    combined = np.concatenate([pre_counts, post_counts])\n",
    "    perm_diffs = []\n",
    "    \n",
    "    for _ in range(n_permutations):\n",
    "        np.random.shuffle(combined)\n",
    "        perm_pre = combined[:len(pre_counts)]\n",
    "        perm_post = combined[len(pre_counts):]\n",
    "        perm_diff = np.mean(perm_post) - np.mean(perm_pre)\n",
    "        perm_diffs.append(perm_diff)\n",
    "    \n",
    "    # Calculate p-value\n",
    "    p_value = np.sum(np.abs(perm_diffs) >= np.abs(actual_diff)) / n_permutations\n",
    "    \n",
    "    return actual_diff, p_value\n",
    "\n",
    "# Example usage:\n",
    "pre_counts = comparison_df['pre_count'].values[:10]\n",
    "post_counts = comparison_df['post_count'].values[:10]\n",
    "\n",
    "actual_diff, p_value = permutation_test_syllables(pre_counts, post_counts)\n",
    "\n",
    "print(f\"Actual Difference: {actual_diff}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Amphetamine Syllable Counts:\n",
      "                             count    count    count    count    count\n",
      "syllable_name                                                         \n",
      "sniff/sit                  31547.0  57626.0  70918.0  47315.0  56914.0\n",
      "sniff/groom                22037.0  38787.0  39055.0  26326.0  38277.0\n",
      "sniff                      10281.0  13097.0  32282.0  70446.0  30260.0\n",
      "sit/pause                   9193.0  11099.0   7204.0   5554.0  18755.0\n",
      "sniff right                 8406.0   8060.0   8561.0   8282.0  13542.0\n",
      "slow walk                   6127.0   6268.0   7661.0   7108.0   5310.0\n",
      "sit                         6121.0   9613.0   6288.0   9881.0   7567.0\n",
      "walk                        4911.0   4392.0   7806.0   6294.0  10397.0\n",
      "sniff left                  4637.0   3717.0   4675.0   4448.0   2899.0\n",
      "pause-walk right            2881.0   2186.0   3067.0   3671.0   5035.0\n",
      "orient left                 1908.0   2654.0   3688.0   4261.0   2419.0\n",
      "groom/sniff/rear            1784.0   7100.0   2430.0   3164.0   3605.0\n",
      "rear/sniff/groom            1173.0   1019.0   1106.0   1174.0   2243.0\n",
      "sniff-orient left            799.0    583.0    285.0    539.0   1219.0\n",
      "left turn                    577.0    217.0   2026.0    826.0    657.0\n",
      "sniff/groom/rear             521.0    779.0   4482.0   3823.0   3243.0\n",
      "walk forward-stop (pause)    247.0    388.0    811.0    357.0    941.0\n",
      "pause-turn right             133.0     85.0    296.0     69.0    313.0\n",
      "left turn                     61.0     45.0    181.0     91.0     50.0\n",
      "right turn-run                55.0      0.0      0.0      0.0      0.0\n",
      "orient right                  50.0    107.0     31.0     15.0     98.0\n",
      "orint left                    31.0     17.0     53.0    123.0    137.0\n",
      "run                           26.0      4.0     20.0     95.0      9.0\n",
      "right turn                    13.0     42.0     15.0     42.0    133.0\n",
      "left turn-run                  0.0      0.0      0.0      0.0     11.0\n",
      "Post-Amphetamine Syllable Counts:\n",
      "                             count  count  count  count    count\n",
      "syllable_name                                                   \n",
      "right turn-run             48946.0   5057   1309   9885  68334.0\n",
      "sit/pause                  34289.0  16257  18138  12221  10324.0\n",
      "walk                       28728.0  14936   9038  19011   3776.0\n",
      "walk forward-stop (pause)  24713.0  15432  25822  33678  25218.0\n",
      "orient right               23259.0  11905   7679   3098  11431.0\n",
      "right turn                 12926.0  57982  26527   5840  25614.0\n",
      "pause-turn right            8421.0  33064  12096   4538  13427.0\n",
      "sniff/groom                 5938.0   2811   4325   8070    737.0\n",
      "sniff                       5549.0   4361   7234  11564   1671.0\n",
      "sniff right                 3791.0   3845   3507   2953   2085.0\n",
      "left turn                   3562.0   4846  11319   6057   2946.0\n",
      "pause-walk right            2890.0   8122   2703   1724    945.0\n",
      "sit                         2361.0   1248   1214   1230   1104.0\n",
      "groom/sniff/rear            1903.0    726   4276   2822   3149.0\n",
      "sniff-orient left           1249.0   3466  12576  17866  10485.0\n",
      "sniff/groom/rear            1213.0   1760   2126   1354   2488.0\n",
      "slow walk                    901.0   5587    212   1272    947.0\n",
      "left turn                    750.0   4170   9410  15173   2260.0\n",
      "rear/sniff/groom             602.0    516   1780   2677   2169.0\n",
      "orient left                  598.0   5729    731   2657   1707.0\n",
      "run                          524.0   5953   1044   4438   3740.0\n",
      "running right turn           148.0     82     44   1261  15773.0\n",
      "sniff left                   120.0    775    233    755    447.0\n",
      "orint left                    90.0    569  12021   6750   1372.0\n",
      "left turn-run                 27.0    639  26963  24751   1401.0\n",
      "sniff/sit                      0.0   1110     78    877      0.0\n",
      "running left run               0.0     85    722   4153    130.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sniff/groom</th>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orient right</th>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sniff right</th>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sit</th>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left turn</th>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sniff left</th>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pause-turn right</th>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk forward-stop (pause)</th>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left turn</th>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sniff-orient left</th>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left turn-run</th>\n",
       "      <td>0.009701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right turn-run</th>\n",
       "      <td>0.009701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sniff/sit</th>\n",
       "      <td>0.011925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right turn</th>\n",
       "      <td>0.011925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slow walk</th>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sniff</th>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orint left</th>\n",
       "      <td>0.031746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sit/pause</th>\n",
       "      <td>0.150794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orient left</th>\n",
       "      <td>0.420635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pause-walk right</th>\n",
       "      <td>0.420635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groom/sniff/rear</th>\n",
       "      <td>0.547619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sniff/groom/rear</th>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rear/sniff/groom</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            p_value\n",
       "sniff/groom                0.007937\n",
       "run                        0.007937\n",
       "orient right               0.007937\n",
       "sniff right                0.007937\n",
       "sit                        0.007937\n",
       "left turn                  0.007937\n",
       "sniff left                 0.007937\n",
       "pause-turn right           0.007937\n",
       "walk forward-stop (pause)  0.007937\n",
       "left turn                  0.007937\n",
       "sniff-orient left          0.007937\n",
       "left turn-run              0.009701\n",
       "right turn-run             0.009701\n",
       "sniff/sit                  0.011925\n",
       "right turn                 0.011925\n",
       "slow walk                  0.015873\n",
       "sniff                      0.015873\n",
       "orint left                 0.031746\n",
       "sit/pause                  0.150794\n",
       "walk                       0.222222\n",
       "orient left                0.420635\n",
       "pause-walk right           0.420635\n",
       "groom/sniff/rear           0.547619\n",
       "sniff/groom/rear           0.690476\n",
       "rear/sniff/groom           1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_syllable_distributions(pre_dfs, post_dfs, column='syllable_name'):\n",
    "    # Create a dictionary to store the test results\n",
    "    results = {}\n",
    "    \n",
    "    # Collect syllable counts for each mouse in both groups\n",
    "    pre_counts = pd.concat([df[column].value_counts() for df in pre_dfs], axis=1).fillna(0)\n",
    "    post_counts = pd.concat([df[column].value_counts() for df in post_dfs], axis=1).fillna(0)\n",
    "    \n",
    "    pre_counts = pre_counts.drop('faulty', errors='ignore')\n",
    "    post_counts = post_counts.drop('faulty', errors='ignore')\n",
    "\n",
    "    # Print the counts for debugging\n",
    "    print(\"Pre-Amphetamine Syllable Counts:\")\n",
    "    print(pre_counts)\n",
    "    \n",
    "    print(\"Post-Amphetamine Syllable Counts:\")\n",
    "    print(post_counts)\n",
    "    \n",
    "    # Perform Mann-Whitney U test for each syllable\n",
    "    for syllable in pre_counts.index:\n",
    "        pre_syllable_counts = pre_counts.loc[syllable].values\n",
    "        post_syllable_counts = post_counts.loc[syllable].values\n",
    "        # print(f\"Syllable: {syllable}, Pre Counts: {pre_syllable_counts}, Post Counts: {post_syllable_counts}\")\n",
    "        stat, p_value = mannwhitneyu(pre_syllable_counts, post_syllable_counts, alternative='two-sided')\n",
    "        results[syllable] = p_value\n",
    "    \n",
    "    # Convert results to a DataFrame for easy viewing\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index', columns=['p_value'])\n",
    "    \n",
    "    # Sort by p-value\n",
    "    results_df = results_df.sort_values(by='p_value')\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Example usage:\n",
    "results_df = compare_syllable_distributions(pre_dfs, post_dfs, column='syllable_name');\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           p_value\n",
      "sniff/sit                   0.0625\n",
      "run                         0.0625\n",
      "orint left                  0.0625\n",
      "orient right                0.0625\n",
      "right turn-run              0.0625\n",
      "left turn                   0.0625\n",
      "pause-turn right            0.0625\n",
      "walk forward-stop (pause)   0.0625\n",
      "left turn                   0.0625\n",
      "sniff-orient left           0.0625\n",
      "right turn                  0.0625\n",
      "left turn-run               0.0625\n",
      "sniff left                  0.0625\n",
      "sit                         0.0625\n",
      "slow walk                   0.0625\n",
      "sniff right                 0.0625\n",
      "sniff                       0.0625\n",
      "sniff/groom                 0.0625\n",
      "walk                        0.1875\n",
      "sit/pause                   0.3125\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "\n",
    "def wilcoxon_signed_rank_test(pre_dfs, post_dfs, column='syllable_name'):\n",
    "    # Create a dictionary to store the test results\n",
    "    results = {}\n",
    "    \n",
    "    # Collect syllable counts for each mouse in both groups\n",
    "    pre_counts = pd.concat([df[column].value_counts() for df in pre_dfs], axis=1).fillna(0)\n",
    "    post_counts = pd.concat([df[column].value_counts() for df in post_dfs], axis=1).fillna(0)\n",
    "    \n",
    "    pre_counts = pre_counts.drop('faulty', errors='ignore')\n",
    "    post_counts = post_counts.drop('faulty', errors='ignore')\n",
    "    # Perform Wilcoxon Signed-Rank Test for each syllable\n",
    "    for syllable in pre_counts.index:\n",
    "        pre_syllable_counts = pre_counts.loc[syllable].values\n",
    "        post_syllable_counts = post_counts.loc[syllable].values\n",
    "        \n",
    "        # Perform the Wilcoxon Signed-Rank Test (for paired data)\n",
    "        try:\n",
    "            stat, p_value = wilcoxon(pre_syllable_counts, post_syllable_counts)\n",
    "            results[syllable] = p_value\n",
    "        except ValueError:\n",
    "            # Handle cases where the data does not vary enough (e.g., all values are zero)\n",
    "            results[syllable] = None\n",
    "    \n",
    "    # Convert results to a DataFrame for easy viewing\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index', columns=['p_value'])\n",
    "    \n",
    "    # Sort by p-value\n",
    "    results_df = results_df.sort_values(by='p_value')\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Example usage:\n",
    "results_df = wilcoxon_signed_rank_test(pre_dfs, post_dfs, column='syllable_name')\n",
    "\n",
    "# Display the test results\n",
    "print(results_df.head(20))  # Show top 10 syllables with the most significant differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_permutation_test(pre_dfs, post_dfs, column='syllable_name', n_permutations=10000, random_state=None):\n",
    "    \"\"\"\n",
    "    Performs a paired permutation test on multivariate syllable count data.\n",
    "\n",
    "    Parameters:\n",
    "    - pre_dfs: List of DataFrames for pre-amphetamine condition (paired by mouse).\n",
    "    - post_dfs: List of DataFrames for post-amphetamine condition (paired by mouse).\n",
    "    - column: Name of the column containing syllable names.\n",
    "    - n_permutations: Number of permutations to perform.\n",
    "    - random_state: Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - observed_stat: Observed sum of squared differences.\n",
    "    - p_value: P-value from the permutation test.\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Ensure the number of pre and post DataFrames are equal (paired)\n",
    "    assert len(pre_dfs) == len(post_dfs), \"Pre and Post DataFrames must be paired and of equal length.\"\n",
    "    n_mice = len(pre_dfs)\n",
    "    \n",
    "    # Identify all unique syllables across all DataFrames, excluding 'faulty'\n",
    "    all_syllables = sorted(set(\n",
    "        syllable for df in pre_dfs + post_dfs\n",
    "        for syllable in df[column].unique() if syllable != 'faulty'\n",
    "    ))\n",
    "    \n",
    "    # Function to extract syllable counts for a single DataFrame\n",
    "    def get_counts(df):\n",
    "        return df[column].value_counts().reindex(all_syllables, fill_value=0).values\n",
    "    \n",
    "    # Extract syllable counts for all mice\n",
    "    pre_counts = np.array([get_counts(df) for df in pre_dfs])  # Shape: (n_mice, n_syllables)\n",
    "    post_counts = np.array([get_counts(df) for df in post_dfs])  # Shape: (n_mice, n_syllables)\n",
    "    \n",
    "    # Calculate observed test statistic (sum of squared differences)\n",
    "    observed_diff = post_counts - pre_counts\n",
    "    observed_stat = np.sum(observed_diff**2)\n",
    "    \n",
    "    # Perform permutation\n",
    "    perm_stats = []\n",
    "    for _ in range(n_permutations):\n",
    "        # For each mouse, decide whether to swap pre and post counts\n",
    "        swap = np.random.choice([True, False], size=n_mice)\n",
    "        perm_post = np.where(swap[:, np.newaxis], pre_counts, post_counts)\n",
    "        perm_pre = np.where(swap[:, np.newaxis], post_counts, pre_counts)\n",
    "        perm_diff = perm_post - perm_pre\n",
    "        perm_stat = np.sum(perm_diff**2)\n",
    "        perm_stats.append(perm_stat)\n",
    "    \n",
    "    perm_stats = np.array(perm_stats)\n",
    "    \n",
    "    # Calculate p-value\n",
    "    p_value = np.mean(perm_stats >= observed_stat)\n",
    "    \n",
    "    return observed_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Statistic: 47193632910\n",
      "P-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Example Usage:\n",
    "# Assuming pre_dfs and post_dfs are lists containing 4 DataFrames each for pre and post conditions.\n",
    "observed_stat, p_value = paired_permutation_test(pre_dfs, post_dfs, column='syllable_name', n_permutations=10000, random_state=42)\n",
    "print(f\"Observed Statistic: {observed_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SUND",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
